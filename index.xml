<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pavani Majety</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Pavani Majety</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Sun, 24 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;h1 id=&#34;pavani-majety&#34;&gt;&#xA;  Pavani Majety&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#pavani-majety&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Hi! I work as a Senior Deep Learning Engineer for Inference Frameworks and Compilers at NVIDIA. I primarily contribute to the inference framework &lt;a href=&#34;https://github.com/vllm-project/vllm&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;vLLM&lt;/a&gt; and the newly released compiler &lt;a href=&#34;https://github.com/NVIDIA/TensorRT-Incubator/tree/main/mlir-tensorrt&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MLIR-TensorRT&lt;/a&gt;. I have previously worked at Mathworks as a Compiler Engineer on the Embedded Coder team. I also did a short stint at Trane as a Software Engineer long time ago.&lt;/p&gt;&#xA;&lt;p&gt;I work on libraries that ensure that LLMs like GPTs, Llamas and Mixtrals give you the best perf when you run on NVIDIA GPUs from any inference framework. I use techniques like Mixed Precision Post Training Quantizations, integrating highly optimized attention implementations like Flash Attention, Flashinfer, etc, and write some CUDA code when required! A major part of ensuring that the perf is great, is to measure perf. I use tools like lm_eval, MLPerf, NSight Systems and NVBench for measuring various aspects of performance of a given model. For less mature spaces like DL Compilers, I also develop and use in-house tools for micro-benchmarking.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pavani Majety&#39;s Resume</title>
      <link>http://localhost:1313/resume/</link>
      <pubDate>Thu, 23 Mar 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/resume/</guid>
      <description>&lt;h3 id=&#34;work-experience&#34;&gt;&#xA;  Work Experience&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#work-experience&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;current-senior-deep-learning-engineer-dl-compilers-nvidia&#34;&gt;&#xA;  (Current) Senior Deep Learning Engineer, DL Compilers, NVIDIA&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#current-senior-deep-learning-engineer-dl-compilers-nvidia&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;p&gt;June 2022 - Present&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Contributed to Tensorflow-TensorRT integration to generate efficient inference code for running on NVIDIA&amp;rsquo;s GPUs, utilizing the TensorRT libraries. My contributions can be found on my github account.&lt;/li&gt;&#xA;&lt;li&gt;Developing ops for a new MLIR dialect that helps convert MHLO / Stable HLO for NVIDIA GPUS with PJRT backend to XLA.&lt;/li&gt;&#xA;&lt;li&gt;(Near future) Contributions to the IREE project from NVIDIA.&lt;/li&gt;&#xA;&lt;li&gt;Mentoring IC1-IC2 engineers through multiple mentorship programs at NVIDIA.&lt;/li&gt;&#xA;&lt;li&gt;Member of WIT Mentorship team at NVIDIA, Women In Compilers and LLVM meetup groups.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;software-engineer--mathworks&#34;&gt;&#xA;  Software Engineer,  Mathworks&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#software-engineer--mathworks&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;p&gt;March 2018 - May 2022&lt;/p&gt;</description>
    </item>
    <item>
      <title>Installing Halide in Ubuntu/Pop OS with vcpkg</title>
      <link>http://localhost:1313/posts/halide_install/</link>
      <pubDate>Sat, 15 Jan 2022 19:40:30 -0500</pubDate>
      <guid>http://localhost:1313/posts/halide_install/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Instructions from Halide blogs&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Install cmake if your don&amp;rsquo;t have it already.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Download the precompiled binaries from: &lt;a href=&#34;https://cmake.org/download/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://cmake.org/download/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;If you prefer installing from the source, follow the instructions on the page.&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;The second step is to install halide with vcpkg. Run the following command once you have installed vcpkg.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./vcpkg/vcpkg install halide:x64-linux&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After some log ..&lt;/p&gt;&#xA;&lt;p&gt;Total elapsed time: 55.61 min&lt;/p&gt;&#xA;&lt;p&gt;The package halide provides CMake targets:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    set(CMAKE_CXX_STANDARD 17)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    set(CMAKE_CXX_STANDARD_REQUIRED YES)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    set(CMAKE_CXX_EXTENSIONS NO)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    find_package(Halide REQUIRED)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    # JIT mode:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    add_executable(my_halide_app main.cpp)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    target_link_libraries(my_halide_app PRIVATE Halide::Halide)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    # AOT mode:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    add_executable(my_generators my_generators.cpp)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    target_link_libraries(my_generators PRIVATE Halide::Generator)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    add_halide_library(my_first_generator FROM my_generators)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    add_halide_library(my_second_generator FROM my_generators&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        PARAMS parallel=false scale=3.0 rotation=ccw output.type=uint16)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    add_halide_library(my_second_generator_2 FROM my_generators&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        GENERATOR my_second_generator&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        PARAMS scale=9.0 rotation=ccw output.type=float32)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    add_halide_library(my_second_generator_3 FROM my_generators&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        GENERATOR my_second_generator&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        PARAMS parallel=false output.type=float64)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;For more information see:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    https://github.com/halide/Halide/blob/v13.0.2/README_cmake.md&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This appears to have installed Halide. To confirm installation, let&amp;rsquo;s try the first tutorial from the halide github page -&lt;/p&gt;</description>
    </item>
    <item>
      <title>Halide</title>
      <link>http://localhost:1313/posts/halide_dsl/</link>
      <pubDate>Sat, 15 Jan 2022 11:29:43 -0500</pubDate>
      <guid>http://localhost:1313/posts/halide_dsl/</guid>
      <description>&lt;p&gt;Sources: &lt;a href=&#34;https://www.youtube.com/watch?v=1ir_nEfKQ7A&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Halide Cpp Con 2020 1&lt;/a&gt;&#xA;&lt;a href=&#34;https://martinfowler.com/bliki/InternalDslStyle.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Martin Fowler Internal DSLs 2&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s talk domain specific languages.. If you don&amp;rsquo;t know about these, let&amp;rsquo;s just say domain specific languages are programming languages that are specialized and restricted to best meet the needs of a specific domain. The goal of a DSL is exploit those restrictions for faster performance, easier maintenance, safety guarentees and so on. The most popular one most of you all know is HTML &amp;ndash; short for HyperText Markup Language. HTML only serves to do one thing - it is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Markup_language&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;markup&#xA;language&amp;rdquo;&lt;/a&gt; that is designed for displaying documents on web browser. You cannot do mathematical computations using HTML.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/</guid>
      <description>&lt;h3 id=&#34;projects&#34;&gt;&#xA;  Projects&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#projects&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;incremental-smoothing-and-mapping-on-umichs-long-term-datasets-2d-lidar-data&#34;&gt;&#xA;  Incremental Smoothing and Mapping on UMich’s Long Term Dataset’s 2D Lidar Data&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#incremental-smoothing-and-mapping-on-umichs-long-term-datasets-2d-lidar-data&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;p&gt;C++, MATLAB&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Spearhead the development effort of our implementation iSAM in C++.&lt;/li&gt;&#xA;&lt;li&gt;Benchmarked our implementation of iSAM with GaTech’s implementation with 2D Lidar data from Victoria Park Dataset and UMLT dataset.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;face-swapping-app&#34;&gt;&#xA;  Face-swapping app&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#face-swapping-app&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h4&gt;&#xA;&lt;p&gt;OpenCV, Python and DLib&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
